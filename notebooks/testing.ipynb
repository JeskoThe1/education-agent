{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from langchain_milvus import Milvus\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv('/home/iliya/education-agent/backend/src/.env')\n",
    "MILVUS_URI = \"./milvus_example.db\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY)\n",
    "\n",
    "def setup_vectorstore():\n",
    "    return Milvus(\n",
    "        embedding_function=OpenAIEmbeddings(OPENAI_API_KEY),\n",
    "        connection_args={\"uri\": MILVUS_URI},\n",
    "        collection_name=\"education_documents\"\n",
    "    )\n",
    "\n",
    "def add_documents_to_vectorstore(vectorstore, documents):\n",
    "    vectorstore.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseModel.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msetup_vectorstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36msetup_vectorstore\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup_vectorstore\u001b[39m():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Milvus(\n\u001b[0;32m---> 10\u001b[0m         embedding_function\u001b[38;5;241m=\u001b[39m\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOPENAI_API_KEY\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     11\u001b[0m         connection_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m\"\u001b[39m: MILVUS_URI},\n\u001b[1;32m     12\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meducation_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseModel.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "setup_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "class LLMInterface:\n",
    "    def __init__(self, model_name=\"gpt-4o\"):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model_name=model_name,\n",
    "            temperature=0.2,\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "\n",
    "    def get_llm(self):\n",
    "        return self.llm\n",
    "\n",
    "    def generate_response(self, prompt):\n",
    "        return self.llm.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len,\n",
    "        )\n",
    "\n",
    "    def process_text(self, text):\n",
    "        return self.text_splitter.split_text(text)\n",
    "\n",
    "    def process_pdf(self, pdf_path):\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages = loader.load_and_split()\n",
    "        return self.text_splitter.split_documents(pages)\n",
    "\n",
    "    def process_all_pdfs(self):\n",
    "        all_docs = []\n",
    "        for filename in os.listdir(\"../data/pdf\"):\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(\"../data/pdf\", filename)\n",
    "                all_docs.extend(self.process_pdf(file_path))\n",
    "        return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "class VectorStore:\n",
    "    def __init__(self):\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = Chroma(\n",
    "            persist_directory=\"./chroma_db\",\n",
    "            embedding_function=self.embeddings\n",
    "        )\n",
    "\n",
    "    def add_texts(self, texts):\n",
    "        self.vectorstore.add_texts(texts)\n",
    "\n",
    "    def add_documents(self, documents):\n",
    "        self.vectorstore.add_documents(documents)\n",
    "\n",
    "    def similarity_search(self, query, k=4):\n",
    "        return self.vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "    def get_retriever(self, k=10):\n",
    "        return self.vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class Retriever:\n",
    "    def __init__(self):\n",
    "        self.retriever = VectorStore().vectorstore.as_retriever()\n",
    "\n",
    "    def format_docs(self, docs):\n",
    "        \"\"\"Formats the retrieved documents into a readable string format.\"\"\"\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    def retrieve_chain(self):\n",
    "        return {\"context\": self.retriever | self.format_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def ensure_directory_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def save_to_json(data, filename):\n",
    "    ensure_directory_exists(\"./data/processed\")\n",
    "    with open(os.path.join(\"./data/processed\", filename), 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def load_from_json(filename):\n",
    "    file_path = os.path.join(\"./data/processed\", filename)\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    return None\n",
    "\n",
    "def save_to_text(data, filename):\n",
    "    ensure_directory_exists(\"./data/processed\")\n",
    "    text_path = os.path.join(\"./data/processed\", filename)\n",
    "    with open(text_path, 'w', encoding='utf-8') as f:\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                f.write(f'{key}: {value}\\n')\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                f.write(f'- {item}\\n')\n",
    "        else:\n",
    "            f.write(str(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "class EducationAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.llm = LLMInterface().get_llm()\n",
    "        self.retriever = VectorStore().get_retriever()\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"country\", \"context\"],\n",
    "            template=\"\"\"\n",
    "            You are an expert in education systems. Your task is to analyze the education system of {country} based strictly on the following information provided:\n",
    "            {context}\n",
    "\n",
    "            In context you will be provided with metadata of the context, with contains sourse, page. Try to make references to that text in your analysis as much as possible. Add to page number 1, so it numbering starts with 1. Reference should be in format: [Document name : page number].\n",
    "            Important: Do not fabricate or infer any data that is not explicitly mentioned in the provided context. Your analysis should be grounded in the given information only. If any details are missing, indicate so without making assumptions.\n",
    "\n",
    "            Provide the analysis in the following format:\n",
    "            1. PISA results (if included in the context)\n",
    "            2. Useful experience for Ukraine\n",
    "            3. Mission and vision (if included in the context)\n",
    "            4. Current development strategies\n",
    "            5. Key features of the education system\n",
    "            6. Key competencies\n",
    "            7. General description of the education system's product\n",
    "            8. Outcomes of this educational system in terms of soft skills. Format the outcomes as a table with 3 columns: how it is formed, the outcome itself, and its generalized name.\n",
    "            \n",
    "            Example table (for Finnish Educational System):\n",
    "            Learning Approach  | Outcome                                                | General Category\n",
    "            ------------------------------------------------------------------------------------------\n",
    "            Inquiry-Based Learning: Finnish education encourages students to ask         | Graduates who can analyze complex situations, generate innovative solutions, and think independently. | Critical Thinking and Problem-Solving Skills\n",
    "            questions, think critically, and engage in problem-solving activities.\n",
    "            Creative Thinking: Emphasis on open-ended tasks and projects fosters          | Graduates skilled in generating creative solutions.                | Innovation and Creativity\n",
    "            creativity and innovation.\n",
    "            Self-Directed Learning: Students are given autonomy to pursue their           | Individuals committed to lifelong learning and adaptable to new     | Lifelong Learning Attitude\n",
    "            interests, promoting intrinsic motivation.                                    | learning opportunities.\n",
    "            \n",
    "            Remember: Do not invent any information. Use only the data given in the context.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "    def analyze_country(self, country):\n",
    "        docs = self.retriever.get_relevant_documents(country)\n",
    "        context = \"\\n\".join([\n",
    "            json.dumps({\n",
    "                \"content\": doc.page_content,\n",
    "                \"metadata\": doc.metadata\n",
    "            }) for doc in docs\n",
    "        ])\n",
    "        chain = self.prompt | self.llm | StrOutputParser()\n",
    "        return chain.invoke({\"country\": country, \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_DOCUMENTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor()\n",
    "vectorstore = VectorStore()\n",
    "education_analyzer = EducationAnalyzer()\n",
    "\n",
    "pdf_data = preprocessor.process_all_pdfs()\n",
    "\n",
    "if ADD_DOCUMENTS:\n",
    "    vectorstore.add_documents(pdf_data)\n",
    "    \n",
    "countries = [\"Finnish\", \"Estonian\", \"Polish\"]\n",
    "analyses = {}\n",
    "for country in countries:\n",
    "    analysis = education_analyzer.analyze_country(country)\n",
    "    save_to_json(analysis, f\"{country.lower()}_analysis.json\")\n",
    "    save_to_text(analysis, f\"{country.lower()}_analysis.txt\")\n",
    "    analyses[country] = analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "education-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
